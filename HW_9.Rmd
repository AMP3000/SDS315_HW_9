---
title: "HW_9"
author: "Advait Phadke"
date: "2025-04-16"
output: pdf_document
---

```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(ggplot2)
library(tidyverse)
library(tibble)
library(knitr)
library(mosaic)
library(MatchIt)
library(effectsize)
```

Advait Phadke, UT EID: amp7984

Github Repo: <https://github.com/AMP3000/SDS315_HW_9/upload>

## Problem 1: Manufacturing Flaws in Circuit Boards

```{r}

data <- read.csv("solder.csv")

```

**Part A**

```{r}
ggplot(data, aes(x = Opening, y = skips)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.6, color = "steelblue") +
  labs(x = "Opening", y = "Skips", title = "Jitter Plot by Opening Size") +
  theme_minimal()
```

This jitter plot shows the number of skips for each circuit board, organized by their opening size (Small, Medium, Large).

```{r}
ggplot(data, aes(x = Solder, y = skips)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.6, color = "coral") +
  labs(x = "Thickness of Alloy", y = "Skips", title = "Jitter Plot by Alloy Thickness", caption = "H") +
  theme_minimal()
```

This jitter plot shows the distribution of skips across all the circuit boards, categorized by whether their solder was thin or thick.

**Part B**

```{r}



lin_model <- lm(skips ~ Opening + Solder + Opening:Solder, data = data)

estimates <- coef(lin_model)
conf_int <- confint(lin_model, level = 0.95)

table <- data.frame(
  Term = names(estimates),
  Estimate = round(estimates, 3),
  `95% CI Lower` = round(conf_int[, 1], 3),
  `95% CI Upper` = round(conf_int[, 2], 3)
)

knitr::kable(
  table,
  caption = "Regression Coefficients Estimate with Respective 95% Confidence Intervals"
)

```

**Part C**

The intercept of 0.393 means the model predicts that when all the baseline conditions are true (opening large, solder thick) then there will be 0.393 skips.

The OpeningM coefficient of 2.407 means that, according to the model, the main effect of the medium opening size is an additional 2.407 skips. This is the effect of medium opening in isolation.

The OpeningS coefficient of 5.127 means that the main effect of the small opening size is an additional 5.127 skips. This is the effect of small opening in isolation.

The SolderThin coefficient of 2.280 means that the main effect of the thin solder is an addition 2.280 skips. This is the effect of thin solder in isolation.

The OpeningM:SolderThin coefficient of -0.740 means that when the opening is medium and the solder is thin, the skips are expected to decrease by 0.740 in comparison to just summing up the individual effects of the medium opening size and thin solder.

The OpeningS:SolderThin coefficient of 9.653 means that when the opening is small and the solder is thin, the skips are expected to increase by 9.653 in comparison to just summing up the individual effects of the small opening size and thin solder.

**Part D**

Based on the linear regression model, I would recommend using a Large opening size along with a thick solder to minimize the amount of skips. This is the baseline used, and all of the coefficients in our model for the other thicknesses and opening sizes are positive increasing the predicted amount of skips, except for the interaction between opening medium and solder thin. But, if we were to use this configuration, the main effects combined with the interaction would still end up being positive and would be expected to increase the number of skips compared to the baseline.

## Problem 2: Grocery Store Prices

```{r}

grocery = read.csv("groceries.csv")

store_prices <- grocery %>%
  group_by(Store) %>%
  summarize(avg_price = mean(Price, na.rm = TRUE))

#head(store_prices)

ggplot(store_prices, aes(x = Store, y = avg_price)) +
  geom_col(fill = "steelblue1") +
  coord_flip() +
  labs(
    title = "Average Price by Store",
    x = "Store",
    y = "Average Price"
  ) +
  theme_minimal()

```

The bar graph above shows the average price of products for each store in the dataset.

```{r, fig.height = 6}

product_data <- grocery %>%
  group_by(Product) %>%
  summarize(stores_selling = n_distinct(Store))

#print (product_data)

ggplot(product_data, aes(x = Product, y = stores_selling)) +
  geom_col(fill = "red") +
  coord_flip() +
  labs(
    title = "Number of Stores Selling Each Product",
    x = "Product",
    y = "Stores Selling"
  ) +
  theme_minimal()

```

The bar graph above shows the number of stores that are selling each product in the dataset

**Part C**

```{r}

linear_model = lm(Price ~ Product + Type, data = grocery)

#confint(linear_model)

```

Compared with ordinary grocery stores (like Albertsons, HEB, or Krogers), convenience stores charge somewhere between \$0.41 and \$0.92 more for the same product.

**Part D**

```{r}

model = lm(Price ~ Product + Store, data = grocery)
#coef(model)
```

Kroger Fresh Fare and Walmart seem to charge the lowest price when comparing the same product. Whole Foods and Wheatsville Food Co-Op seem to charge the highest price when comparing the same product.

**Part E**

The coefficient for HEB is -\$0.65 while the coefficient for Central Market is -\$0.57. Upon first look, these numbers do not seem wildly different, so it seems like Central Market charges a similar price for the same products. The difference is only \$0.08. Many of the other stores have a much larger difference, such as Natural Grocers whose coefficient is -\$0.08 making the difference \$0.57 in comparison to HEB.

**Part F**

```{r}

grocery <- grocery %>%
  mutate(Income10K = trunc(Income/10000))

mod = lm(Price ~ Product + Income10K, data = grocery)
#coef(mod)

#standardize_parameters(mod)

```

The sign of the coefficient on the Income10K variable is negative. Therefore, the model predicts that the higher the income the more the price decreases. This means that according to the model, people in poorer ZIP codes end up paying more for the same product on average. This coefficient just looks at the change in price between different incomes, so product is held constant during this comparison.

A one-standard deviation increase in the income of a ZIP code seems to be associated with\
a -0.03 standard-deviation change in the price that consumers in that ZIP code expect to pay for\
the same product.

## Problem 3: Redlining

A. ZIP codes with a higher percentage of minority residents tend to have more FAIR policies per 100 housing units.

True. As we can see in the scatterplot of % minority residents vs FAIR policies per 100 housing units, there is a moderately strong positive linear relationship between the two variables. The slope of the linear regression line is 0.014, meaning that it predicts that for every 1% increase in minority residents in the total ZIP code's population, the FAIR policies per 100 housing units goes up by 0.014. The r squared of the model is 0.51639, meaning that the model is able to explain 51.64% of the variability we see in y. This is extremely high, but is pretty high, indicating that the model does a decent job of predicting FAIR policies per 100 housing units based on minority residents %. Another important addition is that the confidence interval for the coefficient on minority is (0.009, 0.18). This confidence interval does not include 0, which means that it is not a plausible value in the light of this data. This means that there does appear to be a positive linear relationship between the two variables, validating the given statement.

B. The evidence suggests an interaction effect between minority percentage and the age of the housing stock in the way that these two variables are related to the number of FAIR policies in a ZIP code.\

Undecidable/ambiguous. In order to determine whether there is an interaction, we would want to see some sort of a plot that allows us to compare the difference in FAIR policies per 100 housing units between ZIP codes with old and new houses in both high minority resident percentages and low minority resident percentages. A good way to do this would be through a jitterplot, where we could have two facets, each showing the FAIR policies per 100 housing units for ZIP codes with a high percentage of houses built before WWII and low percentage, where one facet is low minority resident percentage and the other is high. We would have to define some kind of threshold which would define low and high, however. In the plots provided, we do see a scatteplot of % of houses built before WWII and minority residents %. We do see a positive linear relationship which suggests a correlation between the two variables, but that is different from having an interaction.

C. The relationship between minority percentage and number of FAIR policies per 100 housing units is\
stronger in high-fire-risk ZIP codes than in low-fire-risk ZIP codes.\

Undecidable/ambiguous. In order to determine whether this is actually true, we would have to split the dataset into two, and separately fit linear regression models on the low and high fire risk data and compare the R squared. If one is much higher than the other, then the statement would be true. We do see a linear regression model with an interaction term leading to two different lines on the scatterplot, one for high risk and one for low risk. But, the best we can do from this is see if the points in either group have a stronger linear relationship visually. But, in this case, we can't observe much just from doing that. The confidence interval for the interaction coefficient is (-0.012, 0.01), which includes 0, meaning that the interaction between the two variables is not statistically significant. This doesn't directly tell us about low/high fire risk ZIP codes having a stronger or weaker relationship with minority percentage, but it does add a little bit to our analysis in terms of how there doesn't seem to be an interaction between the two variables.

D. Even without controlling for any other variables, income “explains away” all the association between\
minority percentage and FAIR policy uptake.\

False. Explaining away means that when you add a variable to your linear regression model, the slope of the other variable (minority in this case) comes much closer to 0, indicating that the effect was actually due to the new variable. The coefficient on the minority variable changes from 0.014 to 0.01 after adding Income to the linear regression model, so it definitely does not explain away all the association between minority percentage and FAIR policy uptake. The 95% confidence interval for the minority coefficient is (0.004, 0.015), which does not include 0, meaning that there is a positive relationship between minority percentage and FAIR policy uptake. So, it would be more appropriate to say that even without controlling for any other variables, income explains away a portion of the association between minority percentage and FAIR policy uptake.

E. Minority percentage and number of FAIR policies are still associated at the ZIP code level, even after\
controlling for income, fire risk, and housing age.

True. When doing linear regression with just minority percentage predicting FAIR policy uptake, the slope was 0.014. After adding all the variables as predictors (fire risk, income, etc.), the coefficient on the minority percentage variable became 0.008. So, we can say that around 40% of the association was explained away by the other variables. But, 0.008 is still significant. The 95% confidence interval for this coefficient (0.003, 0.014), which does not include 0, meaning that it is not a plausible value. So, there is a relationship between minority percentage and FAIR policy uptake. In addition to this, the percentage of minority residents can range from 0-100, so this means that the FAIR policy uptake can be between 0 and 0.8% different based on the minority percentage, which is actually a big difference as the FAIR policy uptake in all the ZIP codes in the dataset ranges from around 0% to a little over 2%. To solidify this argument, it would be helpful to see standardized coefficients (although we did a similar rudimentary makeshift analysis) or the effect size of each variable.
